{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-27T18:28:31.264210Z","iopub.execute_input":"2021-10-27T18:28:31.264519Z","iopub.status.idle":"2021-10-27T18:28:31.274855Z","shell.execute_reply.started":"2021-10-27T18:28:31.264478Z","shell.execute_reply":"2021-10-27T18:28:31.273921Z"},"trusted":true},"execution_count":208,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn  as sns\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.276417Z","iopub.execute_input":"2021-10-27T18:28:31.276939Z","iopub.status.idle":"2021-10-27T18:28:31.284430Z","shell.execute_reply.started":"2021-10-27T18:28:31.276902Z","shell.execute_reply":"2021-10-27T18:28:31.283471Z"},"trusted":true},"execution_count":209,"outputs":[]},{"cell_type":"markdown","source":"# TASK\n* The goal of this homework is to create a regression model for prediction apartment prices (column 'price').","metadata":{}},{"cell_type":"markdown","source":"## EDA\n### Import Data","metadata":{}},{"cell_type":"code","source":"# Load the data\ncolumns=['latitude','longitude',\n'price',\n'minimum_nights',\n'number_of_reviews',\n'reviews_per_month',\n'calculated_host_listings_count',\n'availability_365'] \ndf=pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv', usecols=columns)\n\ndf.head()\n\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.285550Z","iopub.execute_input":"2021-10-27T18:28:31.285885Z","iopub.status.idle":"2021-10-27T18:28:31.416957Z","shell.execute_reply.started":"2021-10-27T18:28:31.285856Z","shell.execute_reply":"2021-10-27T18:28:31.415058Z"},"trusted":true},"execution_count":210,"outputs":[]},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.419330Z","iopub.execute_input":"2021-10-27T18:28:31.419662Z","iopub.status.idle":"2021-10-27T18:28:31.435699Z","shell.execute_reply.started":"2021-10-27T18:28:31.419616Z","shell.execute_reply":"2021-10-27T18:28:31.434588Z"},"trusted":true},"execution_count":211,"outputs":[]},{"cell_type":"code","source":"sns.histplot(df['price'], bins=50)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.437033Z","iopub.execute_input":"2021-10-27T18:28:31.437664Z","iopub.status.idle":"2021-10-27T18:28:31.832539Z","shell.execute_reply.started":"2021-10-27T18:28:31.437614Z","shell.execute_reply":"2021-10-27T18:28:31.831271Z"},"trusted":true},"execution_count":212,"outputs":[]},{"cell_type":"markdown","source":"The `price` variable has a long tail from the plot above.","metadata":{}},{"cell_type":"markdown","source":"# Question 1\n* Find a feature with missing values. How many missing values does it have?","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()\n\nmissing=df.isnull().mean()*100\nmissing[missing>0]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.833784Z","iopub.execute_input":"2021-10-27T18:28:31.834053Z","iopub.status.idle":"2021-10-27T18:28:31.845951Z","shell.execute_reply.started":"2021-10-27T18:28:31.834020Z","shell.execute_reply":"2021-10-27T18:28:31.844911Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"markdown","source":"The `reviews_per_month` feature has got 10052 missing values.","metadata":{}},{"cell_type":"markdown","source":"### Duplicates","metadata":{}},{"cell_type":"code","source":"df.duplicated().value_counts() # there are no duplicates","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.847505Z","iopub.execute_input":"2021-10-27T18:28:31.847861Z","iopub.status.idle":"2021-10-27T18:28:31.874268Z","shell.execute_reply.started":"2021-10-27T18:28:31.847818Z","shell.execute_reply":"2021-10-27T18:28:31.873336Z"},"trusted":true},"execution_count":214,"outputs":[]},{"cell_type":"markdown","source":"# Question 2\n* What's the median (50% percentile) for variable 'minimum_nights'?\n## Split the data\n* Shuffle the initial dataset, use seed 42.\n* Split your data in train/val/test sets, with 60%/20%/20% distribution.\n* Make sure that the target value ('price') is not in your dataframe.\n* Apply the log transformation to the price variable using the np.log1p() function.","metadata":{}},{"cell_type":"code","source":"df.minimum_nights.median()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.876696Z","iopub.execute_input":"2021-10-27T18:28:31.876951Z","iopub.status.idle":"2021-10-27T18:28:31.883338Z","shell.execute_reply.started":"2021-10-27T18:28:31.876920Z","shell.execute_reply":"2021-10-27T18:28:31.882661Z"},"trusted":true},"execution_count":215,"outputs":[]},{"cell_type":"markdown","source":"### Descriptive Statistics\n\nWe can also use the `describe` function to determine the median","metadata":{}},{"cell_type":"code","source":"df.describe(percentiles=[.0,.25,.5, .75,.9, .95, .99,.1]).T\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.884576Z","iopub.execute_input":"2021-10-27T18:28:31.884836Z","iopub.status.idle":"2021-10-27T18:28:31.944119Z","shell.execute_reply.started":"2021-10-27T18:28:31.884805Z","shell.execute_reply":"2021-10-27T18:28:31.943522Z"},"trusted":true},"execution_count":216,"outputs":[]},{"cell_type":"markdown","source":"As seen the median of the feature is 3.0","metadata":{}},{"cell_type":"markdown","source":"## Data Visualization","metadata":{}},{"cell_type":"code","source":"fig= plt.figure(figsize=(15,10),dpi=100, facecolor=\"white\", edgecolor=\"red\")\n\nax=plt.gca()\n\ndf.hist(bins=100, ax=ax, layout=(3, 3), column=['price','minimum_nights', 'number_of_reviews','reviews_per_month','calculated_host_listings_count','availability_365' ], color='blue')\nplt.tight_layout()\n\nplt.show","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:31.945169Z","iopub.execute_input":"2021-10-27T18:28:31.945716Z","iopub.status.idle":"2021-10-27T18:28:34.764277Z","shell.execute_reply.started":"2021-10-27T18:28:31.945678Z","shell.execute_reply":"2021-10-27T18:28:34.763370Z"},"trusted":true},"execution_count":217,"outputs":[]},{"cell_type":"markdown","source":"This data is not distributed normally. It is quite skewed. Therefore we do the log transformation.","metadata":{}},{"cell_type":"code","source":"sns.distplot(df.price)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:34.766101Z","iopub.execute_input":"2021-10-27T18:28:34.766402Z","iopub.status.idle":"2021-10-27T18:28:35.371963Z","shell.execute_reply.started":"2021-10-27T18:28:34.766360Z","shell.execute_reply":"2021-10-27T18:28:35.370955Z"},"trusted":true},"execution_count":218,"outputs":[]},{"cell_type":"code","source":"sns.distplot(np.log1p(df.price))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:35.373284Z","iopub.execute_input":"2021-10-27T18:28:35.373556Z","iopub.status.idle":"2021-10-27T18:28:36.005576Z","shell.execute_reply.started":"2021-10-27T18:28:35.373512Z","shell.execute_reply":"2021-10-27T18:28:36.004993Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"markdown","source":"It turns into a more normal distribution.","metadata":{}},{"cell_type":"markdown","source":"Let us first create a linear regression function. Get the weights and biases","metadata":{}},{"cell_type":"code","source":"def train_linear_regression(X,y):\n    ones=np.ones(X.shape[0])\n    X=np.column_stack([ones, X])\n    \n    XTX=X.T.dot(X)\n    XTX_inv=np.linalg.inv(XTX)\n    w=XTX_inv.dot(X.T).dot(y)\n    \n    return w[0], w[1:]\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.006518Z","iopub.execute_input":"2021-10-27T18:28:36.007372Z","iopub.status.idle":"2021-10-27T18:28:36.013597Z","shell.execute_reply.started":"2021-10-27T18:28:36.007332Z","shell.execute_reply":"2021-10-27T18:28:36.012462Z"},"trusted":true},"execution_count":220,"outputs":[]},{"cell_type":"markdown","source":"## DataSet Preparation","metadata":{}},{"cell_type":"code","source":"n= len(df)\n\nn_val=int(n*0.2)\n\nn_test=int(n*.2)\n\nn_train=n- (n_val+ n_test)\n\nidx=np.arange(n)\n\nnp.random.seed(42)\n\nnp.random.shuffle(idx)\n\ndf_shuffled=df.iloc[idx]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.014918Z","iopub.execute_input":"2021-10-27T18:28:36.015197Z","iopub.status.idle":"2021-10-27T18:28:36.030223Z","shell.execute_reply.started":"2021-10-27T18:28:36.015145Z","shell.execute_reply":"2021-10-27T18:28:36.029358Z"},"trusted":true},"execution_count":221,"outputs":[]},{"cell_type":"code","source":"df_train=df_shuffled.iloc[:n_train].copy()\ndf_val=df_shuffled.iloc[n_train:n_train+n_val].copy()\ndf_test=df_shuffled.iloc[n_val+n_train:].copy()\n\n\ndf_train=df_train.reset_index(drop=True)\ndf_val=df_val.reset_index(drop=True)\ndf_test=df_test.reset_index(drop=True)\n\ny_train_orig=df_train.price.values\ny_val_orig=df_val.price.values\ny_test_orig=df_test.price.values\n\ny_train=np.log1p(y_train_orig)\ny_val=np.log1p(y_val_orig)\ny_test=np.log1p(y_test_orig)\n\ndf.head(10)\ny_train","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.031877Z","iopub.execute_input":"2021-10-27T18:28:36.032256Z","iopub.status.idle":"2021-10-27T18:28:36.047991Z","shell.execute_reply.started":"2021-10-27T18:28:36.032209Z","shell.execute_reply":"2021-10-27T18:28:36.047143Z"},"trusted":true},"execution_count":222,"outputs":[]},{"cell_type":"code","source":"del df_train['price']\ndel df_val['price']\ndel df_test['price']","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.049284Z","iopub.execute_input":"2021-10-27T18:28:36.049491Z","iopub.status.idle":"2021-10-27T18:28:36.054666Z","shell.execute_reply.started":"2021-10-27T18:28:36.049466Z","shell.execute_reply":"2021-10-27T18:28:36.054086Z"},"trusted":true},"execution_count":223,"outputs":[]},{"cell_type":"markdown","source":"# Question 3\n* We need to deal with missing values for the column from Q1.\n* We have two options: fill it with 0 or with the mean of this variable.\n* Try both options. For each, train a linear regression model without regularization using the code from the lessons.\n* For computing the mean, use the training only!\n* Use the validation dataset to evaluate the models and compare the RMSE of each option.\n* Round the RMSE scores to 2 decimal digits using round(score, 2)\n* Which option gives better RMSE?","metadata":{}},{"cell_type":"code","source":"base=['latitude','longitude',\n'minimum_nights',\n'number_of_reviews',\n'reviews_per_month',\n'calculated_host_listings_count',\n'availability_365']\n\n\ndef prepare_X(df, fillna_value):\n    \n    df_num=df[base]\n    \n    df_num=df_num.fillna(fillna_value)\n    \n    X=df_num.values\n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.055872Z","iopub.execute_input":"2021-10-27T18:28:36.056148Z","iopub.status.idle":"2021-10-27T18:28:36.065899Z","shell.execute_reply.started":"2021-10-27T18:28:36.056116Z","shell.execute_reply":"2021-10-27T18:28:36.065275Z"},"trusted":true},"execution_count":224,"outputs":[]},{"cell_type":"code","source":"def rmse (y_pred, y):\n    error=y_pred-y\n    mse=(error ** 2).mean()\n    \n    return np.sqrt(mse)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.066968Z","iopub.execute_input":"2021-10-27T18:28:36.067430Z","iopub.status.idle":"2021-10-27T18:28:36.077650Z","shell.execute_reply.started":"2021-10-27T18:28:36.067394Z","shell.execute_reply":"2021-10-27T18:28:36.077043Z"},"trusted":true},"execution_count":225,"outputs":[]},{"cell_type":"code","source":"mean=df_train['reviews_per_month'].mean()\n\nX_mean_train=prepare_X(df_train, fillna_value=mean)\n\nw0_mean, w_mean=train_linear_regression(X_mean_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.078706Z","iopub.execute_input":"2021-10-27T18:28:36.079060Z","iopub.status.idle":"2021-10-27T18:28:36.105148Z","shell.execute_reply.started":"2021-10-27T18:28:36.079028Z","shell.execute_reply":"2021-10-27T18:28:36.104116Z"},"trusted":true},"execution_count":226,"outputs":[]},{"cell_type":"code","source":"X_mean_val=prepare_X(df_val, fillna_value=mean)\n\ny_mean_pred_val=w0_mean + X_mean_val.dot(w_mean)\n\ny_mean_pred_val","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.113102Z","iopub.execute_input":"2021-10-27T18:28:36.113554Z","iopub.status.idle":"2021-10-27T18:28:36.126913Z","shell.execute_reply.started":"2021-10-27T18:28:36.113505Z","shell.execute_reply":"2021-10-27T18:28:36.126019Z"},"trusted":true},"execution_count":227,"outputs":[]},{"cell_type":"code","source":"np.round(rmse(y_mean_pred_val, y_val),2) #Using the mean","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.128698Z","iopub.execute_input":"2021-10-27T18:28:36.129336Z","iopub.status.idle":"2021-10-27T18:28:36.137644Z","shell.execute_reply.started":"2021-10-27T18:28:36.129283Z","shell.execute_reply":"2021-10-27T18:28:36.136445Z"},"trusted":true},"execution_count":228,"outputs":[]},{"cell_type":"markdown","source":"Now using 0 so that we can compare","metadata":{}},{"cell_type":"code","source":"fillna_value=0\n\nX_0_train=prepare_X(df_train, fillna_value=0)\n\nw0_0, w_0=train_linear_regression(X_0_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.141873Z","iopub.execute_input":"2021-10-27T18:28:36.142928Z","iopub.status.idle":"2021-10-27T18:28:36.162741Z","shell.execute_reply.started":"2021-10-27T18:28:36.142860Z","shell.execute_reply":"2021-10-27T18:28:36.161259Z"},"trusted":true},"execution_count":229,"outputs":[]},{"cell_type":"code","source":"X_0_val=prepare_X(df_val, fillna_value=0)\n\ny_0_pred_val=w0_0 + X_0_val.dot(w_0)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.165354Z","iopub.execute_input":"2021-10-27T18:28:36.166375Z","iopub.status.idle":"2021-10-27T18:28:36.178588Z","shell.execute_reply.started":"2021-10-27T18:28:36.166314Z","shell.execute_reply":"2021-10-27T18:28:36.177391Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"np.round(rmse(y_0_pred_val, y_val),2)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.180793Z","iopub.execute_input":"2021-10-27T18:28:36.181612Z","iopub.status.idle":"2021-10-27T18:28:36.190459Z","shell.execute_reply.started":"2021-10-27T18:28:36.181560Z","shell.execute_reply":"2021-10-27T18:28:36.189397Z"},"trusted":true},"execution_count":231,"outputs":[]},{"cell_type":"markdown","source":"## Answer 3: They are similar.","metadata":{}},{"cell_type":"markdown","source":"# Question 4\n* Now let's train a regularized linear regression.\n* For this question, fill the NAs with 0.\n* Try different values of r from this list: [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10].\n* Use RMSE to evaluate the model on the validation dataset.\n* Round the RMSE scores to 2 decimal digits.\n* Which r gives the best RMSE?","metadata":{}},{"cell_type":"code","source":"def train_linear_regression(X, y, r=0.0):\n    ones=np.ones(X.shape[0])\n    X=np.column_stack([ones, X])\n    \n    XTX=X.T.dot(X)\n    XTX= XTX + r * np.eye(XTX.shape[0])\n    XTX_inv=np.linalg.inv(XTX)\n    w=XTX_inv.dot(X.T).dot(y)\n    \n    return w[0], w[1:]\n    ","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.192464Z","iopub.execute_input":"2021-10-27T18:28:36.193066Z","iopub.status.idle":"2021-10-27T18:28:36.204189Z","shell.execute_reply.started":"2021-10-27T18:28:36.193017Z","shell.execute_reply":"2021-10-27T18:28:36.203039Z"},"trusted":true},"execution_count":232,"outputs":[]},{"cell_type":"code","source":"# Loop over a list  of r's to determine the best value\n\nfor r in [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n    \n    w_0, w= train_linear_regression(X_0_train, y_train, r=r)\n    \n    y_0_reg_val=w_0 + X_0_val.dot(w)\n    \n    score=np.round(rmse(y_0_reg_val, y_val),2)\n    \n    print(f\"For {r} value the bias term is {w_0:.4f} and  rsme is {score}\")\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.206243Z","iopub.execute_input":"2021-10-27T18:28:36.206885Z","iopub.status.idle":"2021-10-27T18:28:36.246058Z","shell.execute_reply.started":"2021-10-27T18:28:36.206833Z","shell.execute_reply":"2021-10-27T18:28:36.245115Z"},"trusted":true},"execution_count":233,"outputs":[]},{"cell_type":"markdown","source":"We can chose to fill the null values with O or the mean of the values.","metadata":{}},{"cell_type":"markdown","source":"## Answer4: 0 gives the best RMSE","metadata":{}},{"cell_type":"markdown","source":"# Question 5\n* We used seed 42 for splitting the data. Let's find out how selecting the seed influences our score.\n* Try different seed values: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9].\n* For each seed, do the train/validation/test split with 60%/20%/20% distribution.\n* Fill the missing values with 0 and train a model without regularization.\n* For each seed, evaluate the model on the validation dataset and collect the RMSE scores.\n* What's the standard deviation of all the scores? To compute the standard deviation, use `np.std`.\n* Round the result to 3 decimal digits (round(std, 3))\n>Note: Standard deviation shows how different the values are. If it's low, then all values are approximately the same. If it's high, the values are different. If standard deviation of scores is low, then our model is stable.","metadata":{}},{"cell_type":"markdown","source":"## Seed Checking","metadata":{}},{"cell_type":"code","source":"rmse_list=[] # we will poplulate this list with rmse values\n\n\nfor s in  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]:\n    \n    idx=np.arange(n)\n    np.random.seed(s)\n    np.random.shuffle(idx)\n    \n    \n    df_shuffled=df.iloc[idx]\n    df_train=df_shuffled.iloc[:n_train].copy()\n    df_val=df_shuffled.iloc[n_train:n_train+n_val].copy()\n    df_test=df_shuffled.iloc[n_val+n_train:].copy()\n    \n    df_train=df_train.reset_index(drop=True)\n    df_val=df_val.reset_index(drop=True)\n    df_test=df_test.reset_index(drop=True)\n\n    y_train_orig=df_train.price.values\n    y_val_orig=df_val.price.values\n    y_test_orig=df_test.price.values\n\n    y_train=np.log1p(y_train_orig)\n    y_val=np.log1p(y_val_orig)\n    y_test=np.log1p(y_test_orig)\n    \n    del df_train['price']\n    del df_val['price']\n    del df_test['price']\n    \n    \n    X_0_train=prepare_X(df_train, fillna_value=0)\n    \n    w_0, w=train_linear_regression(X_0_train, y_train)\n    \n    X_0_val=prepare_X(df_val, fillna_value=0)\n    \n    y_0_val_reg=w_0 +X_0_val.dot(w)\n    \n    \n    rmse_scores=np.round(rmse(y_0_val_reg, y_val),2)\n    \n    rmse_list.append(rmse_scores)\n    \n    \n    print(s, w_0  , rmse_scores )","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.247858Z","iopub.execute_input":"2021-10-27T18:28:36.248446Z","iopub.status.idle":"2021-10-27T18:28:36.531153Z","shell.execute_reply.started":"2021-10-27T18:28:36.248394Z","shell.execute_reply":"2021-10-27T18:28:36.530271Z"},"trusted":true},"execution_count":234,"outputs":[]},{"cell_type":"code","source":"# The standard deviation rounded to 3 decimal places\n\nnp.round(np.std(rmse_list), 3)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.532905Z","iopub.execute_input":"2021-10-27T18:28:36.533574Z","iopub.status.idle":"2021-10-27T18:28:36.544286Z","shell.execute_reply.started":"2021-10-27T18:28:36.533519Z","shell.execute_reply":"2021-10-27T18:28:36.543298Z"},"trusted":true},"execution_count":235,"outputs":[]},{"cell_type":"markdown","source":"##### Answer 5: The standard deviation is .008","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question 6\n* Split the dataset like previously, use seed 9.\n* Combine train and validation datasets.\n* Fill the missing values with 0 and train a model with r=0.001.\n* What's the RMSE on the test dataset?","metadata":{}},{"cell_type":"markdown","source":"### Seed and Regularization","metadata":{}},{"cell_type":"code","source":"s=9\n\nidx=np.arange(n)\n\nnp.random.seed(s)\n\nnp.random.shuffle(idx)\n\ndf_shuffled=df.iloc[idx]\n\ndf_train=df_shuffled.iloc[:n_train].copy()\ndf_val=df_shuffled.iloc[n_train:n_train+n_val].copy()\ndf_test=df_shuffled.iloc[n_val+n_train:].copy()\n\n\ndf_full=[df_train,df_val]\n\ndf_full=pd.concat(df_full)\n\ndf_full=df_full.reset_index(drop=True)\ndf_test=df_test.reset_index(drop=True)\n\ny_train_val_orig=df_full.price.values\ny_test_orig=df_test.price.values\n\n\ny_train_val=np.log1p(y_train_val_orig)\ny_test=np.log1p(y_test_orig)\n\n\ndel df_full['price']\ndel df_test['price']\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.546142Z","iopub.execute_input":"2021-10-27T18:28:36.546739Z","iopub.status.idle":"2021-10-27T18:28:36.581180Z","shell.execute_reply.started":"2021-10-27T18:28:36.546686Z","shell.execute_reply":"2021-10-27T18:28:36.580147Z"},"trusted":true},"execution_count":236,"outputs":[]},{"cell_type":"code","source":"X_0_full=prepare_X(df_full, fillna_value=0)\n\nw_0_full, w_full=train_linear_regression(X_0_full, y_train_val, r=.001)\n\n\nX_0_test=prepare_X(df_test, fillna_value=0)\ny_0_pred_test= w_0_full + X_0_test.dot(w_full)\n\n\n\n\nnp.round(rmse(y_test,y_0_pred_test), 2)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.583010Z","iopub.execute_input":"2021-10-27T18:28:36.583647Z","iopub.status.idle":"2021-10-27T18:28:36.610812Z","shell.execute_reply.started":"2021-10-27T18:28:36.583595Z","shell.execute_reply":"2021-10-27T18:28:36.609803Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"home=df_test.iloc[5609].to_dict()\nhome","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.612652Z","iopub.execute_input":"2021-10-27T18:28:36.613288Z","iopub.status.idle":"2021-10-27T18:28:36.625594Z","shell.execute_reply.started":"2021-10-27T18:28:36.613236Z","shell.execute_reply":"2021-10-27T18:28:36.624446Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"df_small=pd.DataFrame([home])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.631597Z","iopub.execute_input":"2021-10-27T18:28:36.635106Z","iopub.status.idle":"2021-10-27T18:28:36.644426Z","shell.execute_reply.started":"2021-10-27T18:28:36.635032Z","shell.execute_reply":"2021-10-27T18:28:36.643380Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"X_small=prepare_X(df_small, fillna_value=0)\n\n\ny_pred=w_0_full + X_small.dot(w_full) \n\n\ny_pred=y_pred[0]\n\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.651704Z","iopub.execute_input":"2021-10-27T18:28:36.652897Z","iopub.status.idle":"2021-10-27T18:28:36.666379Z","shell.execute_reply.started":"2021-10-27T18:28:36.652835Z","shell.execute_reply":"2021-10-27T18:28:36.665443Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"np.expm1(y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.668231Z","iopub.execute_input":"2021-10-27T18:28:36.668691Z","iopub.status.idle":"2021-10-27T18:28:36.677614Z","shell.execute_reply.started":"2021-10-27T18:28:36.668639Z","shell.execute_reply":"2021-10-27T18:28:36.676544Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"np.expm1(y_test[5609])","metadata":{"execution":{"iopub.status.busy":"2021-10-27T18:28:36.679337Z","iopub.execute_input":"2021-10-27T18:28:36.680838Z","iopub.status.idle":"2021-10-27T18:28:36.692149Z","shell.execute_reply.started":"2021-10-27T18:28:36.680779Z","shell.execute_reply":"2021-10-27T18:28:36.691185Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"markdown","source":"#### Answer no 6: is 0.65","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}